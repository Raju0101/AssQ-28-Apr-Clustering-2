{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2677454-b110-419a-aad8-4ee709f9de47",
   "metadata": {},
   "source": [
    "# AssQ-28-April-ML-Clustering-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc92d66-c188-4714-a7ce-d8e47f5fddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57640572-e208-4f96-9281-903a2b723dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a form of clustering algorithm that produces 1 to n clusters, where n represents the number of observations in a data set.\n",
    "There are two types of hierarchical clustering, divisive (top-down) and agglomerative (bottom-up).\n",
    "\n",
    "Hierarchical clustering is a popular method for grouping objects.\n",
    "It creates groups so that objects within a group are similar to each other and different from objects in other groups. \n",
    "Clusters are visually represented in a hierarchical tree called a dendrogram.\n",
    "\n",
    "The difference between Kmeans and hierarchical clustering is that in Kmeans clustering,\n",
    "the number of clusters is pre-defined and is denoted by “K”, but in hierarchical clustering, \n",
    "the number of sets is either one or similar to the number of data observations.\n",
    "\n",
    "Hierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. For example, \n",
    "all files and folders on the hard disk are organized in a hierarchy. There are two types of hierarchical clustering\n",
    "\n",
    "Two types of clustering algorithms are nonhierarchical and hierarchical. \n",
    "In nonhierarchical clustering, such as the k-means algorithm, the relationship between clusters is undetermined.\n",
    "Hierarchical clustering repeatedly links pairs of clusters until every data object is included in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0409b-f792-4770-b8a0-e8ca1444479c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569c1ba-ebc2-497f-b571-29ce821ffae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28d4a5-c496-43b8-b123-1771d86efaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are two types of hierarchical clustering: divisive (top-down) and agglomerative (bottom-up).\n",
    "\n",
    "There are two major types of approaches in hierarchical clustering:\n",
    "Agglomerative clustering: Divide the data points into different clusters and then aggregate them as the distance decreases. \n",
    "Divisive clustering: Combine all the data points as a single cluster and divide them as the distance between them increases.\n",
    "\n",
    "The divisive clustering algorithm is a top-down clustering approach,\n",
    "initially,  all the points in the dataset belong to one cluster\n",
    "and split is performed recursively as one moves down the hierarchy.\n",
    "\n",
    "Everyone in the old party asks himself: “In average, do I hate others\n",
    "in old party more than hating the members in the new party?”\n",
    "If the answer is “Yes”, then he will also go to the new party.\n",
    "\n",
    "DIANA is a hierarchical clustering technique which constructs the hierarchy in the inverse order.\n",
    "It approaches the reversal algorithm of Agglomerative Hierarchical Clustering.\n",
    "There is one large cluster consisting of all n objects.\n",
    "\n",
    "Agglomerative Clustering is a type of hierarchical clustering algorithm.\n",
    "It is an unsupervised machine learning technique that divides the population into several clusters such that data points in \n",
    "the same cluster are more similar and data points in different clusters are dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b85be0-ffea-4eba-8392-19451728b9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27dfd79-88ca-4673-a16c-4fa7308016f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the \n",
    "common distance metrics used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0a906-1860-43ce-b7e4-d19ea800bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "For most common hierarchical clustering software, the default distance measure is the Euclidean distance.\n",
    "This is the square root of the sum of the square differences.\n",
    "However, for gene expression, correlation distance is often used.\n",
    "\n",
    "In complete linkage hierarchical clustering, the distance between two clusters is defined \n",
    "as the longest distance between two points in each cluster. For example, the distance between \n",
    "clusters “r” and “s” to the left is equal to the length of the arrow between their two furthest points.\n",
    "\n",
    "In Average linkage clustering, the distance between two clusters is defined as\n",
    "the average of distances between all pairs of objects, where each pair is made up of one object from each group.\n",
    "\n",
    "D(r,s) = Trs / ( Nr * Ns) \n",
    "Where Trs is the sum of all pairwise distances between cluster r and cluster s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ec908-c8b9-4753-bd13-2848fd47198d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b02c3-0c61-468a-9e9d-b4020961cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some \n",
    "common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25bf7b-4309-426a-8c18-d9ffd2e38df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "To get the optimal number of clusters for hierarchical clustering, we make use a dendrogram which is\n",
    "tree-like chart that shows the sequences of merges or splits of clusters. If two clusters are merged,\n",
    "the dendrogram will join them in a graph and the height of the join will be the distance between those clusters.\n",
    "\n",
    "methods to determine number of clusters?\n",
    "Image result for Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some \n",
    "common methods used for this purpose?\n",
    "Contents\n",
    "1 Elbow method.\n",
    "2 X-means clustering.\n",
    "3 Information criterion approach.\n",
    "4 Information–theoretic approach.\n",
    "5 Silhouette method.\n",
    "6 Cross-validation.\n",
    "7 Finding number of clusters in text databases.\n",
    "8 Analyzing the kernel matrix.\n",
    "\n",
    "The optimal number of clusters can be defined as follow:\n",
    "Compute clustering algorithm (e.g., k-means clustering) for different values of k. ...\n",
    "For each k, calculate the total within-cluster sum of square (wss).\n",
    "Plot the curve of wss according to the number of clusters k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9342542-e3a9-4f3b-a126-d2f8b30b59f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a25df8-ec88-4967-9fad-03a186f82728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac49edd-e492-4c8e-b0cb-e59944a5e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "A dendrogram is a tree-like structure that explains the relationship between all the\n",
    "data points in the system. However, like a regular family tree, a dendrogram need not\n",
    "branch out at regular intervals from top to bottom as the vertical direction\n",
    "(y-axis) in it represents the distance between clusters in some metric.\n",
    "\n",
    "A dendrogram is a diagram that shows the hierarchical relationship between objects.\n",
    "It is most commonly created as an output from hierarchical clustering. \n",
    "The main use of a dendrogram is to work out the best way to allocate objects to clusters.\n",
    "\n",
    "The key to interpreting a hierarchical cluster analysis is to look at the point at which any\n",
    "given pair of cards “join together” in the tree diagram. \n",
    "Cards that join together sooner are more similar to each other than those that join together later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9337959-eb30-4c72-98dc-96ec06319cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d9242-9338-4739-b208-e960487f2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the \n",
    "distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8ea18-fe9a-4364-a8ce-9b7254db58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfortunately, the majority of clustering algorithms can only work with data that exclusively \n",
    "contains either numeric or categorical features.\n",
    "This is a huge problem, as most real world datasets will contain multiple types of features.\n",
    "\n",
    "Most distance metrics, and hence the hierarchical clustering methods, work either with continuous-only or categorical-only data.\n",
    "In applications, however, observations are often described by a combination of both continuous and categorical variables.\n",
    "\n",
    "The k-Prototype algorithm is an extension to the k-Modes algorithm that combines the k-modes and k-means algorithms and \n",
    "is able to cluster mixed numerical and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de72ec-5f0b-4f28-bea4-c0086d64308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4cfd9-81cd-445b-b033-e9caa1e2cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708f40e-a770-4347-8a58-a8d7128a8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Find out the threshold value for the dataset. If threshold value is greater than the distance \n",
    "than this object is consider as outlier. In cluster based approach find out smallest cluster and \n",
    "consider those objects in smallest cluster as outlier, it acts as a data reduction.\n",
    "\n",
    "Simple statistical techniques such as mean, median, quantiles can be used to detect\n",
    "univariate anomalies feature values in the dataset. Various data visualization and\n",
    "exploratory data analysis techniques can be also be used to detect anomalies.\n",
    "\n",
    "We identify outliers as those observations in a cluster with minimal membership proportion or for\n",
    "which the cluster-specific variance with and without the observation is very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3ef0a-7f06-406e-b339-dca68144d5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa5517-e08e-4ab9-8a3e-e277f2af133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728e684-f3e4-4db0-b74b-ca90f6e3c77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021833f-e06e-43e5-a612-456084243aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47129b7c-3820-4e9f-b5d4-2bbb0da27553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e81f5-1ca9-4c65-8dcf-b26a286dc7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6853c4-6b5a-4cd7-8f95-c200bbcc8147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cf21c-b22f-4f31-b023-bd63c303bca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9b807-a841-4322-a31e-ca209551b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b168a-bbc0-4255-8751-f40f40972775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
